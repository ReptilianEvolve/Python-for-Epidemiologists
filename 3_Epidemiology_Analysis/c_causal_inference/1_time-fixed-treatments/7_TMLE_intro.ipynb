{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted Maximum Likelihood Estimator\n",
    "The targeted maximum likelihood estimator (TMLE) is a doubly robust estimator. What distinguishes it from other doubly robust estimators (augmented-IPTW) is that it uses a secondary targeting (hence the name) step that optimizes the bias-variance tradeoff for the target parameter. A common target parameter is the sample average treatment effect, which compares to counterfactual where all individuals in the study sample were treated versus the counterfactual where no individual was treated. Throughout this section, I will use the notation that is common in the TMLE literature. This is a little different from the notation in other documents.\n",
    "\n",
    "The target parameter is defined as\n",
    "$$\\psi = E_L\\left[E\\left[Y^{a=1}|L\\right] - E\\left[Y^{a=0}|L\\right]\\right]$$\n",
    "We will focus on this parameter, but other estimates (like risk ratio and odds ratio) are also implemented\n",
    "\n",
    "This tutorial provides a basic introduction to fitting TMLE using *zEpid*. Additionally, I demonstrate how to use machine learning algorithms / super learner to estimate `TMLE` with less restrictive functional form assumptions\n",
    "\n",
    "## Doubly Robust Estimators\n",
    "Before continuing, I will briefly outline what a doubly-robust estimator is and why you would want to use one. In observational research with high-dimensional data, we (generally) are forced to use parametric models to adjust for many confounders. In this scenario, we assume that our parametric models are correctly specified. Our statistical model, $\\mathcal{M}$, must include the distribution that the data came from. \n",
    "\n",
    "With other estimators, like IPTW or g-formula, we have one chance to specify $\\mathcal{M}$ correctly. Doubly-robust estimators use a model to predict the treatment (like IPTW) and another model to predict the outcome (like g-formula). The estimator then combines the estimates, such that if either is correct, then our estimate will be consistent. Essentially, we get two chances to get the statistical model correct.\n",
    "\n",
    "A more in-depth description of doubly robust estimators is available in [this pre-print](https://statnav.files.wordpress.com/2017/10/doublerobustness-preprint.pdf)\n",
    "\n",
    "## TMLE Procedure\n",
    "I will briefly outline how TMLE (complete-case) is estimated.\n",
    "\n",
    "1) Initial estimates for $Y$ are predicted from a statistical model. Predicted values of $Y$ are generated for each treatment $Y^{a=1}$ and $Y^{a=0}$. This is commonly refered to as $Q_0$\n",
    "$$E\\left[Y | A, L\\right]$$\n",
    "\n",
    "2) Predicted probabilities of treatment are estimated from a second statistical model. \n",
    "$$\\Pr(A=1|L)$$\n",
    "\n",
    "3) Using the predicted probabilities from step 2, we calculate what is referred to as the \"clever covariate\". Clever covariates are calculated for each individual using the following formula\n",
    "$$ H(A=a,L) = \\frac{I(A=1)}{\\pi_1} - \\frac{I(A=0)}{\\pi_0}$$\n",
    "\n",
    "4) Calculate the updated counterfactual outcomes $Q_n$ through the targeting step. For a single targeting step, we fit the following logistic regression model\n",
    "$$logit\\left(E(Y|A,L)\\right) = logit(\\hat{Y}^a) + \\sigma * H$$\n",
    "where the predicted outcome is an offset. \n",
    "\n",
    "5) From the targeting step, we predict the targeted estimate via\n",
    "$$\\hat{Y}_*^1 = logit(\\hat{Y}^1) + \\sigma * H(A=1,L)$$\n",
    "$$\\hat{Y}_*^0 = logit(\\hat{Y}^0) + \\sigma * H(A=0,L)$$\n",
    "then from the predicted individual outcomes, we generate the target parameter using\n",
    "$$\\psi = \\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{Y}_*^1 - \\hat{Y}_*^0\\right)$$\n",
    "\n",
    "For a more indepth discussion, please refer to [Schuler and Rose 2017](https://academic.oup.com/aje/article/185/1/65/2662306)\n",
    "\n",
    "## An example\n",
    "To motivate our example, we will use a simulated data set included with *zEpid*. In the data set, we have a cohort of HIV-positive individuals. We are interested in the sample average treatment effect of antiretroviral therapy (ART) on all-cause mortality at 45-weeks. Based on substantive background knowledge, we believe that the treated and untreated population are exchangeable based gender, age, CD4 T-cell count, and detectable viral load. \n",
    "\n",
    "In this tutorial, we will focus on a complete case analysis. Therefore, we will drop the `cd4_wk45` column and all the missing data in `dead`. This will leave 517 observations with no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 517 entries, 0 to 546\n",
      "Data columns (total 12 columns):\n",
      "id         517 non-null int64\n",
      "male       517 non-null int64\n",
      "age0       517 non-null int64\n",
      "cd40       517 non-null int64\n",
      "dvl0       517 non-null int64\n",
      "art        517 non-null int64\n",
      "dead       517 non-null float64\n",
      "t          517 non-null float64\n",
      "age_rs1    517 non-null float64\n",
      "age_rs2    517 non-null float64\n",
      "cd4_rs1    517 non-null float64\n",
      "cd4_rs2    517 non-null float64\n",
      "dtypes: float64(6), int64(6)\n",
      "memory usage: 52.5 KB\n"
     ]
    }
   ],
   "source": [
    "from zepid import load_sample_data, spline\n",
    "from zepid.causal.doublyrobust import TMLE\n",
    "\n",
    "df = load_sample_data(False)\n",
    "df[['age_rs1', 'age_rs2']] = spline(df, 'age0', n_knots=3, term=2, restricted=True)\n",
    "df[['cd4_rs1', 'cd4_rs2']] = spline(df, 'cd40', n_knots=3, term=2, restricted=True)\n",
    "\n",
    "dfcc = df.drop(columns=['cd4_wk45']).dropna()\n",
    "dfcc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready to conduct a complete case analysis using TMLE. First, we initialize TMLE with our complete-case data (`dfcc`), the treatment (`art`), and the outcome (`dead`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tml = TMLE(dfcc, exposure='art', outcome='dead')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment Model\n",
    "As the first step, we will estimate the treatment model. We believe the sufficient set for the treatment model is gender (`male`), age (`age0`), CD4 T-cell (`cd40`) and detectable viral load (`dvl0`). To relax the functional for assumptions, we will model age and CD4 using restricted quadratic splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "MODEL: art ~ male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0\n",
      "-----------------------------------------------------------------\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                    art   No. Observations:                  517\n",
      "Model:                            GLM   Df Residuals:                      508\n",
      "Model Family:                Binomial   Df Model:                            8\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -206.06\n",
      "Date:                Wed, 24 Apr 2019   Deviance:                       412.12\n",
      "Time:                        13:36:11   Pearson chi2:                     510.\n",
      "No. Iterations:                     5   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4498      1.679      0.864      0.388      -1.841       4.741\n",
      "male          -0.1159      0.321     -0.361      0.718      -0.745       0.513\n",
      "age0          -0.1026      0.059     -1.726      0.084      -0.219       0.014\n",
      "age_rs1        0.0048      0.003      1.706      0.088      -0.001       0.010\n",
      "age_rs2       -0.0077      0.006     -1.373      0.170      -0.019       0.003\n",
      "cd40           0.0041      0.004      0.964      0.335      -0.004       0.012\n",
      "cd4_rs1    -2.422e-05    1.2e-05     -2.014      0.044   -4.78e-05   -6.49e-07\n",
      "cd4_rs2     8.875e-05   4.55e-05      1.952      0.051   -3.81e-07       0.000\n",
      "dvl0          -0.0158      0.399     -0.040      0.968      -0.797       0.765\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "tml.exposure_model('male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TMLE` uses a logistic regression model to estimate the probabilities of treatment and the corresponding summary of the model fit are printed to the console. \n",
    "\n",
    "### Outcome Model\n",
    "Now, we will estimate the outcome model. We will model the outcomes as ART (`art`), gender (`male`), age (`age0`), CD4 T-cell (`cd40`) and detectable viral load (`dvl0`). Again, we will model age and CD4 using restricted quadratic splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "MODEL: dead ~ male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0\n",
      "-----------------------------------------------------------------\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   dead   No. Observations:                  517\n",
      "Model:                            GLM   Df Residuals:                      508\n",
      "Model Family:                Binomial   Df Model:                            8\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -204.76\n",
      "Date:                Wed, 24 Apr 2019   Deviance:                       409.52\n",
      "Time:                        13:36:11   Pearson chi2:                     511.\n",
      "No. Iterations:                     6   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -4.2878      2.700     -1.588      0.112      -9.581       1.005\n",
      "male          -0.1008      0.330     -0.306      0.760      -0.747       0.545\n",
      "age0           0.1616      0.096      1.688      0.091      -0.026       0.349\n",
      "age_rs1       -0.0059      0.004     -1.508      0.132      -0.013       0.002\n",
      "age_rs2        0.0130      0.006      2.050      0.040       0.001       0.025\n",
      "cd40          -0.0123      0.004     -3.041      0.002      -0.020      -0.004\n",
      "cd4_rs1     2.015e-05   1.17e-05      1.721      0.085    -2.8e-06    4.31e-05\n",
      "cd4_rs2    -4.464e-05   4.59e-05     -0.973      0.330      -0.000    4.53e-05\n",
      "dvl0          -0.1056      0.396     -0.267      0.790      -0.882       0.671\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "tml.outcome_model('male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a binary outcome is input, `TMLE` uses a logistic regression to estimate the probabilities of the outcome. Model output is printed to the console by default.\n",
    "\n",
    "### Targeting step\n",
    "The targeting step and estimation is done through the `fit()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tml.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view our results after the targeting step by using the `summary()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                Targeted Maximum Likelihood Estimator                 \n",
      "======================================================================\n",
      "Treatment:        art             No. Observations:     517                 \n",
      "Outcome:          dead            No. Missing Outcome:  0                   \n",
      "g-Model:          Logistic        Missing Model:        None                \n",
      "Q-Model:          Logistic       \n",
      "======================================================================\n",
      "Risk Difference:     -0.084\n",
      "95.0% two-sided CI: (-0.153 , -0.015)\n",
      "----------------------------------------------------------------------\n",
      "Risk Ratio:          0.536\n",
      "95.0% two-sided CI: (0.28 , 1.025)\n",
      "----------------------------------------------------------------------\n",
      "Odds Ratio:          0.486\n",
      "95.0% two-sided CI: (0.235 , 1.003)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "tml.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results indicate that had everyone in our cohort been given ART at diagnosis the incidence of all-cause mortality at 45 weeks would have been -8.4% (95% CL: -0.153, -0.015) lower compared to if everyone have not been given ART. Based on these results, we would suggest ART should be given to all newly diagnosed HIV-infected individuals.\n",
    "\n",
    "As seen, `TMLE` estimates other common target parameters of interest by default. Confidence intervals are estimated using efficient influence curves. At this point in my understanding, I cannot tell you much about influence curves or the theory underlying them. However, they rely on projection of higher dimensional functions on lower dimensional space (think 2D shadows of 3D objects)\n",
    "\n",
    "## Tuning Parameters\n",
    "Luckily in our example, we don't have an issue estimating the predicted probabilities of ART. This can possibly cause issues in the estimation procedure. One solution is to \"trim\" the estimated propensity scores. This is commonly used in propensity score and IPTW methods. By using the `bound` optional argument in the `exposure_model()` function, we can restrict the predicted probabilities. \n",
    "\n",
    "As demonstration, we will restrict to predicted probabilties of treatment between 0.01 to 0.99. Asymmetrical bounds can also be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                Targeted Maximum Likelihood Estimator                 \n",
      "======================================================================\n",
      "Treatment:        art             No. Observations:     517                 \n",
      "Outcome:          dead            No. Missing Outcome:  0                   \n",
      "g-Model:          Logistic        Missing Model:        None                \n",
      "Q-Model:          Logistic       \n",
      "======================================================================\n",
      "Risk Difference:     -0.082\n",
      "95.0% two-sided CI: (-0.154 , -0.009)\n",
      "----------------------------------------------------------------------\n",
      "Risk Ratio:          0.552\n",
      "95.0% two-sided CI: (0.285 , 1.07)\n",
      "----------------------------------------------------------------------\n",
      "Odds Ratio:          0.502\n",
      "95.0% two-sided CI: (0.239 , 1.054)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "tml = TMLE(dfcc, exposure='art', outcome='dead')\n",
    "tml.exposure_model('male + age0 + cd40 + cd4_rs1 + cd4_rs2 + dvl0', bound=[0.01, 0.99], print_results=False)\n",
    "tml.outcome_model('art + male + age0 + cd40 + cd4_rs1 + cd4_rs2 + dvl0', print_results=False)\n",
    "tml.fit()\n",
    "tml.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When restricting the probabilities in our example, similar results are obtained. Caution should be used when using this argument. This approach may \"smooth\" over important outliers or change the generalizability/transportability of your results. This should be considered as a last option if you have trouble estimating TMLE.\n",
    "\n",
    "## Machine Learning\n",
    "Previously we used the default statistical model of `TMLE`. One of the major advantages of `TMLE` is the ability to use machine learning models to estimate a causal effect. Methods like the g-formula can use machine learning to estimate point-estimates, but certain algorithms are invalid for bootstrapping. We are unable to obtain valid confidence intervals. TMLE, through efficient influence curves, allows us to obtain valid confidence intervals from machine learning algorithms without bootstrapping. \n",
    "\n",
    "I will demonstrate TMLE with super learner. Super learner is a generalized stacking algorith. Briefly, super learner allows us to specify a few different machine learning algorithm options. Based on cross-validated standard errors, the best performing machine learning algorithms are selected. An extensive discussion of how super learner works and how it is estimated is available here: [Rose 2013](https://academic.oup.com/aje/article/177/5/443/141300). The Python implementation of super learner I will use can be downloaded from [this GitHub repo](https://github.com/alexpkeil1/SuPyLearner). It is not currently available through PyPI.\n",
    "\n",
    "To use machine learning models, we set up the models to be estimated (everything before `fit()` is called). Then we can estimate the algorithms by specifying `custom_model` in the corresponding model statments. Currently, `TMLE` supports `supylearner` and `sklearn` algorithms. If you have a library of machine learning algorithms you would like to see implemented, please let me know on GitHub and I can work on adding support.\n",
    "\n",
    "For our example, we will use a neural network, L1-penalized logistic regression model, L2-penalized logistic regression model, random forest, AdaBoost, and Naive Bayes. These algorithms will be used for both the exposure and outcome models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                Targeted Maximum Likelihood Estimator                 \n",
      "======================================================================\n",
      "Treatment:        art             No. Observations:     517                 \n",
      "Outcome:          dead            No. Missing Outcome:  0                   \n",
      "g-Model:          User-specified  Missing Model:        None                \n",
      "Q-Model:          User-specified \n",
      "======================================================================\n",
      "Risk Difference:     -0.081\n",
      "95.0% two-sided CI: (-0.15 , -0.012)\n",
      "----------------------------------------------------------------------\n",
      "Risk Ratio:          0.555\n",
      "95.0% two-sided CI: (0.297 , 1.038)\n",
      "----------------------------------------------------------------------\n",
      "Odds Ratio:          0.505\n",
      "95.0% two-sided CI: (0.25 , 1.019)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import supylearner\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initializing the ML algorithms\n",
    "neural = MLPClassifier(hidden_layer_sizes=(8,), random_state=1463)\n",
    "log1 = LogisticRegression(penalty='l1', random_state=201)\n",
    "log2 = LogisticRegression(penalty='l2', random_state=103)\n",
    "randf = RandomForestClassifier(random_state=141)\n",
    "adaboost = AdaBoostClassifier(random_state=505)\n",
    "bayes = GaussianNB()\n",
    "\n",
    "# Initializing SuPyLearner with the above algorithms\n",
    "lib = [neural, log1, log2, randf, adaboost, bayes]\n",
    "libnames = [\"Neural-Net\", \"Log_L1\", \"Log_L2\", \"Random Forest\", \"AdaBoost\", \"Bayes\"]\n",
    "sl = supylearner.SuperLearner(lib, libnames, loss=\"nloglik\", K=10, print_results=False)\n",
    "\n",
    "# Estimating TMLE with ML algorithms\n",
    "tmle = TMLE(dfcc, exposure='art', outcome='dead')  # Step 1) Initialize TMLE class\n",
    "tmle.exposure_model('male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0',\n",
    "                    custom_model=sl, print_results=False)  # Step 2) Specify exposure model\n",
    "tmle.outcome_model('art + male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0',\n",
    "                   custom_model=sl, print_results=False)  # Step 3) Specify outcome model\n",
    "tmle.fit()  # Step 4) Targeting step\n",
    "tmle.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TMLE with super learner produces similar results. This suggests we did a decent job of specifying the functional form our parametric models. In the next tutorials, we will outline how to handle missing outcome data and continuous outcomes.\n",
    "\n",
    "# Conclusion\n",
    "In this tutorial, I have described TMLE and its usage in *zEpid*. In this tutorial, I have focused on a complete case analysis for a binary outcome with both parametric logistic regression models and machine learning algorithms. In the next tutorials, we will review how to use `TMLE` with missing outcome data and `TMLE` for continuous outcomes.\n",
    "\n",
    "## References\n",
    "\n",
    "Schuler, Megan S., and Sherri Rose. \"Targeted maximum likelihood estimation for causal inference in observational studies.\" American Journal of Epidemiology 185.1 (2017): 65-73.\n",
    "\n",
    "van der Laan, Mark J., and Sherri Rose. Targeted learning: causal inference for observational and experimental data. Springer Science & Business Media, 2011.\n",
    "\n",
    "van Der Laan, Mark J., and Daniel Rubin. \"Targeted maximum likelihood learning.\" The International Journal of Biostatistics 2.1 (2006).\n",
    "\n",
    "Gruber, S., & van der Laan, M. J. (2011). tmle: An R package for targeted maximum likelihood estimation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
