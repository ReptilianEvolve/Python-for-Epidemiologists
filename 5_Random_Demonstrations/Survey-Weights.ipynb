{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the Importance of Survey Weights\n",
    "\n",
    "Below is a simple simulation study demonstrating why it is important to use survey weights when estimating the population average treatment effect (PATE). This is also demonstrated with loss-to-follow-up (LTFU). The main takeaway is that survey weights are necessary for estimation of the PATE when the study population is not a random sample of the target population. Additionally, survey weights cannot correct for informative LTFU, so we need inverse probability of censoring weights (IPCW).\n",
    "\n",
    "### Data Generating Mechanisms\n",
    "\n",
    "1) Non-informative LTFU & random sample of the target population\n",
    "\n",
    "2) Non-informative LTFU & non-random sample of the target population\n",
    "\n",
    "3) Informative LTFU & random sample of the target population\n",
    "\n",
    "4) Informative LTFU & non-random sample of the target population\n",
    "\n",
    "Below are the elements of the data generating mechanism that are constant across scenarios\n",
    "$$W \\sim \\text{Bernoulli}(0.5)$$\n",
    "$$L \\sim \\text{Bernoulli}(0.5)$$\n",
    "$$A \\sim \\text{Bernoulli}(0.5)$$\n",
    "\n",
    "$$Y \\sim 100 + 5 A - 6 W A + 5 W - 7 L A + N(0, 10)$$\n",
    "\n",
    "### Estimation\n",
    "We will look at four different approaches for estimation:\n",
    "\n",
    "1) Naive estimator (GLM) that ignores sampling and censoring\n",
    "\n",
    "2) IPCW (GEE) accounts for informative censoring\n",
    "\n",
    "3) IPSW (GEE) accounts for non-random sampling\n",
    "\n",
    "4) IPCW * IPSW (GEE) accounts for informative censoring and non-random sampling\n",
    "\n",
    "### Note on PATE\n",
    "For the PATE, a sample is used to estimate the ATE for a target population of interest. Under this model of inference, we only observed a small fraction of the target population. The PATE is in contrast to the sample average treatment effect (SATE), in which the study sample *is* the target population (i.e. we observed the entire target population at baseline).\n",
    "\n",
    "### Simulation Set-up\n",
    "The four scenarios are simulated 2000 times for a sample size of 1000. Information regarding bias, empirical standard error (ESE), 95% confidence limit coverage, and confidence limit differences were summarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import logistic\n",
    "\n",
    "ind = sm.cov_struct.Independence()\n",
    "f = sm.families.family.Gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "n = 1000000\n",
    "sims = 2000\n",
    "sample_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-informative LTFU & Censoring\n",
    "Under this data generating mechanism, there is non-informative LTFU and the study sample is a random sample of the target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000133403656929\n"
     ]
    }
   ],
   "source": [
    "# Generating Super-Population\n",
    "df = pd.DataFrame()\n",
    "# Baseline Variables\n",
    "df['W'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['A'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['L'] = np.random.binomial(1, p=0.5, size=n)\n",
    "# Potential Outcomes\n",
    "df['Y1'] = 100 + 5*1 - 6*df['W'] + 5*1*df['W'] - 7*1*df['L'] + np.random.normal(0, 10, size=n)\n",
    "df['Y0'] = 100 + 5*0 - 6*df['W'] + 5*0*df['W'] - 7*0*df['L'] + np.random.normal(0, 10, size=n)\n",
    "truth = np.mean(df['Y1'] - df['Y0'])\n",
    "print(truth)\n",
    "\n",
    "# Causal Consistency\n",
    "df['Y'] = df['Y1'] * df['A'] + df['Y0'] * (1 - df['A'])\n",
    "# Pre-Determined Censoring\n",
    "df['C'] = np.random.binomial(1, p=logistic.cdf(-1.2), size=n)\n",
    "df['Y'] = np.where(df['C']==1, np.nan, df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_naive = []; cover_naive = []; cld_naive = []\n",
    "bias_ipcw = []; cover_ipcw = []; cld_ipcw = []\n",
    "bias_ipsw = []; cover_ipsw = []; cld_ipsw = []\n",
    "bias_full = []; cover_full = []; cld_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prop = 0.5\n",
    "\n",
    "for i in range(sims):\n",
    "    # Simulating Uneven sample selection\n",
    "    dfw1 = df.loc[df['W'] == 1].copy()\n",
    "    sfw1 = dfw1.sample(n=int(sample_size*sample_prop))\n",
    "\n",
    "    dfw0 = df.loc[df['W'] == 0].copy()\n",
    "    sfw0 = dfw0.sample(n=int(sample_size*(1-sample_prop)))\n",
    "    dfs = pd.concat([sfw1, sfw0])\n",
    "\n",
    "    # Naive Estimator (doesn't account for sampling or LTFU\n",
    "    fm = smf.glm(\"Y ~ A\", dfs, family=f).fit()\n",
    "    bias_naive.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_naive.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_naive.append(1)\n",
    "    else:\n",
    "        cover_naive.append(0)\n",
    "\n",
    "    # IPCW-only\n",
    "    dfs['ipcw'] = 1 / np.where(dfs['L']==0, 1-np.mean(dfs.loc[dfs[\"L\"]==0, 'C']), 1-np.mean(dfs.loc[dfs[\"L\"]==1, 'C']))\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipcw']).fit()\n",
    "    bias_ipcw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipcw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipcw.append(1)\n",
    "    else:\n",
    "        cover_ipcw.append(0)\n",
    "\n",
    "    # IPSW-only\n",
    "    dfs['ipsw'] = 1 / np.where(dfs['W']==1, sample_prop, 1-sample_prop)\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipsw']).fit()\n",
    "    bias_ipsw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipsw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipsw.append(1)\n",
    "    else:\n",
    "        cover_ipsw.append(0)\n",
    "\n",
    "    # IPCW & IPSW\n",
    "    dfs['full_ipw'] = dfs['ipcw'] * dfs['ipsw']\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['full_ipw']).fit()\n",
    "    bias_full.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_full.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_full.append(1)\n",
    "    else:\n",
    "        cover_full.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Naive\n",
      "-----------------------------------------\n",
      "Bias: -0.020955875930596012\n",
      "ESE: 0.7556524283755429\n",
      "CLD: 2.980379354114867\n",
      "Coverage: 0.9465\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW\n",
      "-----------------------------------------\n",
      "Bias: -0.020406523780216027\n",
      "ESE: 0.7524331876882983\n",
      "CLD: 2.976864579952081\n",
      "Coverage: 0.947\n",
      "=========================================\n",
      "=========================================\n",
      "IPSW\n",
      "-----------------------------------------\n",
      "Bias: -0.02095587593059538\n",
      "ESE: 0.7556524283755427\n",
      "CLD: 2.976346846555782\n",
      "Coverage: 0.9465\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW & IPSW\n",
      "-----------------------------------------\n",
      "Bias: -0.020406523780216027\n",
      "ESE: 0.7524331876882983\n",
      "CLD: 2.976864579952081\n",
      "Coverage: 0.947\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Summarizing Results\n",
    "print(\"=========================================\")\n",
    "print(\"Naive\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_naive))\n",
    "print(\"ESE:\", np.std(bias_naive, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_naive))\n",
    "print(\"Coverage:\", np.mean(cover_naive))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipcw))\n",
    "print(\"ESE:\", np.std(bias_ipcw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipcw))\n",
    "print(\"Coverage:\", np.mean(cover_ipcw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipsw))\n",
    "print(\"ESE:\", np.std(bias_ipsw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipsw))\n",
    "print(\"Coverage:\", np.mean(cover_ipsw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW & IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_full))\n",
    "print(\"ESE:\", np.std(bias_full, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_full))\n",
    "print(\"Coverage:\", np.mean(cover_full))\n",
    "print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-informative LTFU & non-random sampling\n",
    "Under this data generating mechanism, there is non-informative LTFU and the study sample is a non-random sample of the target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.011276651714743\n"
     ]
    }
   ],
   "source": [
    "# Generating Super-Population\n",
    "df = pd.DataFrame()\n",
    "# Baseline Variables\n",
    "df['W'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['A'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['L'] = np.random.binomial(1, p=0.5, size=n)\n",
    "# Potential Outcomes\n",
    "df['Y1'] = 100 + 5*1 - 6*df['W'] + 5*1*df['W'] - 7*1*df['L'] + np.random.normal(0, 10, size=n)\n",
    "df['Y0'] = 100 + 5*0 - 6*df['W'] + 5*0*df['W'] - 7*0*df['L'] + np.random.normal(0, 10, size=n)\n",
    "truth = np.mean(df['Y1'] - df['Y0'])\n",
    "print(truth)\n",
    "\n",
    "# Causal Consistency\n",
    "df['Y'] = df['Y1'] * df['A'] + df['Y0'] * (1 - df['A'])\n",
    "# Pre-Determined Censoring\n",
    "df['C'] = np.random.binomial(1, p=logistic.cdf(-1.2), size=n)\n",
    "df['Y'] = np.where(df['C']==1, np.nan, df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_naive = []; cover_naive = []; cld_naive = []\n",
    "bias_ipcw = []; cover_ipcw = []; cld_ipcw = []\n",
    "bias_ipsw = []; cover_ipsw = []; cld_ipsw = []\n",
    "bias_full = []; cover_full = []; cld_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prop = 0.75\n",
    "\n",
    "for i in range(sims):\n",
    "    # Simulating Uneven sample selection\n",
    "    dfw1 = df.loc[df['W'] == 1].copy()\n",
    "    sfw1 = dfw1.sample(n=int(sample_size*sample_prop))\n",
    "\n",
    "    dfw0 = df.loc[df['W'] == 0].copy()\n",
    "    sfw0 = dfw0.sample(n=int(sample_size*(1-sample_prop)))\n",
    "    dfs = pd.concat([sfw1, sfw0])\n",
    "\n",
    "    # Naive Estimator (doesn't account for sampling or LTFU\n",
    "    fm = smf.glm(\"Y ~ A\", dfs, family=f).fit()\n",
    "    bias_naive.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_naive.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_naive.append(1)\n",
    "    else:\n",
    "        cover_naive.append(0)\n",
    "\n",
    "    # IPCW-only\n",
    "    dfs['ipcw'] = 1 / np.where(dfs['L']==0, 1-np.mean(dfs.loc[dfs[\"L\"]==0, 'C']), 1-np.mean(dfs.loc[dfs[\"L\"]==1, 'C']))\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipcw']).fit()\n",
    "    bias_ipcw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipcw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipcw.append(1)\n",
    "    else:\n",
    "        cover_ipcw.append(0)\n",
    "\n",
    "    # IPSW-only\n",
    "    dfs['ipsw'] = 1 / np.where(dfs['W']==1, sample_prop, 1-sample_prop)\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipsw']).fit()\n",
    "    bias_ipsw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipsw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipsw.append(1)\n",
    "    else:\n",
    "        cover_ipsw.append(0)\n",
    "\n",
    "    # IPCW & IPSW\n",
    "    dfs['full_ipw'] = dfs['ipcw'] * dfs['ipsw']\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['full_ipw']).fit()\n",
    "    bias_full.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_full.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_full.append(1)\n",
    "    else:\n",
    "        cover_full.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Naive\n",
      "-----------------------------------------\n",
      "Bias: 1.2208519101185373\n",
      "ESE: 0.7489535125526047\n",
      "CLD: 2.9619757253094923\n",
      "Coverage: 0.632\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW\n",
      "-----------------------------------------\n",
      "Bias: 1.2250502066873636\n",
      "ESE: 0.749541614123929\n",
      "CLD: 2.9588040873807975\n",
      "Coverage: 0.6325\n",
      "=========================================\n",
      "=========================================\n",
      "IPSW\n",
      "-----------------------------------------\n",
      "Bias: -0.003596668469659017\n",
      "ESE: 0.8675267198202137\n",
      "CLD: 3.42995888648739\n",
      "Coverage: 0.9515\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW & IPSW\n",
      "-----------------------------------------\n",
      "Bias: 0.0005054891252299746\n",
      "ESE: 0.8685548269525982\n",
      "CLD: 3.4305541728477666\n",
      "Coverage: 0.9515\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Summarizing Results\n",
    "print(\"=========================================\")\n",
    "print(\"Naive\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_naive))\n",
    "print(\"ESE:\", np.std(bias_naive, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_naive))\n",
    "print(\"Coverage:\", np.mean(cover_naive))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipcw))\n",
    "print(\"ESE:\", np.std(bias_ipcw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipcw))\n",
    "print(\"Coverage:\", np.mean(cover_ipcw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipsw))\n",
    "print(\"ESE:\", np.std(bias_ipsw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipsw))\n",
    "print(\"Coverage:\", np.mean(cover_ipsw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW & IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_full))\n",
    "print(\"ESE:\", np.std(bias_full, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_full))\n",
    "print(\"Coverage:\", np.mean(cover_full))\n",
    "print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informative LTFU & random sampling\n",
    "Under this data generating mechanism, there is informative LTFU and the study sample is a random sample of the target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.015146792348841\n"
     ]
    }
   ],
   "source": [
    "# Generating Super-Population\n",
    "df = pd.DataFrame()\n",
    "# Baseline Variables\n",
    "df['W'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['A'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['L'] = np.random.binomial(1, p=0.5, size=n)\n",
    "# Potential Outcomes\n",
    "df['Y1'] = 100 + 5*1 - 6*df['W'] + 5*1*df['W'] - 7*1*df['L'] + np.random.normal(0, 10, size=n)\n",
    "df['Y0'] = 100 + 5*0 - 6*df['W'] + 5*0*df['W'] - 7*0*df['L'] + np.random.normal(0, 10, size=n)\n",
    "truth = np.mean(df['Y1'] - df['Y0'])\n",
    "print(truth)\n",
    "\n",
    "# Causal Consistency\n",
    "df['Y'] = df['Y1'] * df['A'] + df['Y0'] * (1 - df['A'])\n",
    "# Pre-Determined Censoring\n",
    "df['C'] = np.random.binomial(1, p=logistic.cdf(-2.2 + 2.0*df['L']), size=n)\n",
    "df['Y'] = np.where(df['C']==1, np.nan, df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_naive = []; cover_naive = []; cld_naive = []\n",
    "bias_ipcw = []; cover_ipcw = []; cld_ipcw = []\n",
    "bias_ipsw = []; cover_ipsw = []; cld_ipsw = []\n",
    "bias_full = []; cover_full = []; cld_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prop = 0.5\n",
    "\n",
    "for i in range(sims):\n",
    "    # Simulating Uneven sample selection\n",
    "    dfw1 = df.loc[df['W'] == 1].copy()\n",
    "    sfw1 = dfw1.sample(n=int(sample_size*sample_prop))\n",
    "\n",
    "    dfw0 = df.loc[df['W'] == 0].copy()\n",
    "    sfw0 = dfw0.sample(n=int(sample_size*(1-sample_prop)))\n",
    "    dfs = pd.concat([sfw1, sfw0])\n",
    "\n",
    "    # Naive Estimator (doesn't account for sampling or LTFU\n",
    "    fm = smf.glm(\"Y ~ A\", dfs, family=f).fit()\n",
    "    bias_naive.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_naive.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_naive.append(1)\n",
    "    else:\n",
    "        cover_naive.append(0)\n",
    "\n",
    "    # IPCW-only\n",
    "    dfs['ipcw'] = 1 / np.where(dfs['L']==0, 1-np.mean(dfs.loc[dfs[\"L\"]==0, 'C']), 1-np.mean(dfs.loc[dfs[\"L\"]==1, 'C']))\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipcw']).fit()\n",
    "    bias_ipcw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipcw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipcw.append(1)\n",
    "    else:\n",
    "        cover_ipcw.append(0)\n",
    "\n",
    "    # IPSW-only\n",
    "    dfs['ipsw'] = 1 / np.where(dfs['W']==1, sample_prop, 1-sample_prop)\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipsw']).fit()\n",
    "    bias_ipsw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipsw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipsw.append(1)\n",
    "    else:\n",
    "        cover_ipsw.append(0)\n",
    "\n",
    "    # IPCW & IPSW\n",
    "    dfs['full_ipw'] = dfs['ipcw'] * dfs['ipsw']\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['full_ipw']).fit()\n",
    "    bias_full.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_full.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_full.append(1)\n",
    "    else:\n",
    "        cover_full.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Naive\n",
      "-----------------------------------------\n",
      "Bias: 0.8464003935084513\n",
      "ESE: 0.795066219299912\n",
      "CLD: 3.0593458524204156\n",
      "Coverage: 0.805\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW\n",
      "-----------------------------------------\n",
      "Bias: -0.0003727648490452893\n",
      "ESE: 0.817389243343777\n",
      "CLD: 3.154250713081465\n",
      "Coverage: 0.9435\n",
      "=========================================\n",
      "=========================================\n",
      "IPSW\n",
      "-----------------------------------------\n",
      "Bias: 0.8464003935084504\n",
      "ESE: 0.795066219299911\n",
      "CLD: 3.05523110080282\n",
      "Coverage: 0.8035\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW & IPSW\n",
      "-----------------------------------------\n",
      "Bias: -0.0003727648490452893\n",
      "ESE: 0.817389243343777\n",
      "CLD: 3.154250713081465\n",
      "Coverage: 0.9435\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Summarizing Results\n",
    "print(\"=========================================\")\n",
    "print(\"Naive\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_naive))\n",
    "print(\"ESE:\", np.std(bias_naive, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_naive))\n",
    "print(\"Coverage:\", np.mean(cover_naive))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipcw))\n",
    "print(\"ESE:\", np.std(bias_ipcw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipcw))\n",
    "print(\"Coverage:\", np.mean(cover_ipcw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipsw))\n",
    "print(\"ESE:\", np.std(bias_ipsw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipsw))\n",
    "print(\"Coverage:\", np.mean(cover_ipsw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW & IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_full))\n",
    "print(\"ESE:\", np.std(bias_full, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_full))\n",
    "print(\"Coverage:\", np.mean(cover_full))\n",
    "print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informative LTFU & non-random sampling\n",
    "Under this data generating mechanism, there is informative LTFU and the study sample is a non-random sample of the target population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.000945415598562\n"
     ]
    }
   ],
   "source": [
    "# Generating Super-Population\n",
    "df = pd.DataFrame()\n",
    "# Baseline Variables\n",
    "df['W'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['A'] = np.random.binomial(1, p=0.5, size=n)\n",
    "df['L'] = np.random.binomial(1, p=0.5, size=n)\n",
    "# Potential Outcomes\n",
    "df['Y1'] = 100 + 5*1 - 6*df['W'] + 5*1*df['W'] - 7*1*df['L'] + np.random.normal(0, 10, size=n)\n",
    "df['Y0'] = 100 + 5*0 - 6*df['W'] + 5*0*df['W'] - 7*0*df['L'] + np.random.normal(0, 10, size=n)\n",
    "truth = np.mean(df['Y1'] - df['Y0'])\n",
    "print(truth)\n",
    "\n",
    "# Causal Consistency\n",
    "df['Y'] = df['Y1'] * df['A'] + df['Y0'] * (1 - df['A'])\n",
    "# Pre-Determined Censoring\n",
    "df['C'] = np.random.binomial(1, p=logistic.cdf(-2.2 + 2.0*df['L']), size=n)\n",
    "df['Y'] = np.where(df['C']==1, np.nan, df['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_naive = []; cover_naive = []; cld_naive = []\n",
    "bias_ipcw = []; cover_ipcw = []; cld_ipcw = []\n",
    "bias_ipsw = []; cover_ipsw = []; cld_ipsw = []\n",
    "bias_full = []; cover_full = []; cld_full = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prop = 0.75\n",
    "\n",
    "for i in range(sims):\n",
    "    # Simulating Uneven sample selection\n",
    "    dfw1 = df.loc[df['W'] == 1].copy()\n",
    "    sfw1 = dfw1.sample(n=int(sample_size*sample_prop))\n",
    "\n",
    "    dfw0 = df.loc[df['W'] == 0].copy()\n",
    "    sfw0 = dfw0.sample(n=int(sample_size*(1-sample_prop)))\n",
    "    dfs = pd.concat([sfw1, sfw0])\n",
    "\n",
    "    # Naive Estimator (doesn't account for sampling or LTFU\n",
    "    fm = smf.glm(\"Y ~ A\", dfs, family=f).fit()\n",
    "    bias_naive.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_naive.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_naive.append(1)\n",
    "    else:\n",
    "        cover_naive.append(0)\n",
    "\n",
    "    # IPCW-only\n",
    "    dfs['ipcw'] = 1 / np.where(dfs['L']==0, 1-np.mean(dfs.loc[dfs[\"L\"]==0, 'C']), 1-np.mean(dfs.loc[dfs[\"L\"]==1, 'C']))\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipcw']).fit()\n",
    "    bias_ipcw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipcw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipcw.append(1)\n",
    "    else:\n",
    "        cover_ipcw.append(0)\n",
    "\n",
    "    # IPSW-only\n",
    "    dfs['ipsw'] = 1 / np.where(dfs['W']==1, sample_prop, 1-sample_prop)\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['ipsw']).fit()\n",
    "    bias_ipsw.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_ipsw.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_ipsw.append(1)\n",
    "    else:\n",
    "        cover_ipsw.append(0)\n",
    "\n",
    "    # IPCW & IPSW\n",
    "    dfs['full_ipw'] = dfs['ipcw'] * dfs['ipsw']\n",
    "    dfsc = dfs.loc[dfs['Y'].notnull()].copy()\n",
    "    fm = smf.gee(\"Y ~ A\", dfsc.index, dfsc, cov_struct=ind, family=f, weights=dfsc['full_ipw']).fit()\n",
    "    bias_full.append(fm.params[\"A\"] - truth)\n",
    "    lcl = fm.conf_int()[0][\"A\"]\n",
    "    ucl = fm.conf_int()[1][\"A\"]\n",
    "    cld_full.append(ucl - lcl)\n",
    "    if lcl < truth < ucl:\n",
    "        cover_full.append(1)\n",
    "    else:\n",
    "        cover_full.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Naive\n",
      "-----------------------------------------\n",
      "Bias: 2.133929385008799\n",
      "ESE: 0.7713515451176863\n",
      "CLD: 3.049320515042233\n",
      "Coverage: 0.223\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW\n",
      "-----------------------------------------\n",
      "Bias: 1.2918697231055307\n",
      "ESE: 0.7869786354377762\n",
      "CLD: 3.1429809565490276\n",
      "Coverage: 0.64\n",
      "=========================================\n",
      "=========================================\n",
      "IPSW\n",
      "-----------------------------------------\n",
      "Bias: 0.8977468318183642\n",
      "ESE: 0.9004980171559569\n",
      "CLD: 3.528635608536402\n",
      "Coverage: 0.833\n",
      "=========================================\n",
      "=========================================\n",
      "IPCW & IPSW\n",
      "-----------------------------------------\n",
      "Bias: 0.05556283511430471\n",
      "ESE: 0.9176393997484601\n",
      "CLD: 3.635175625112106\n",
      "Coverage: 0.952\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Summarizing Results\n",
    "print(\"=========================================\")\n",
    "print(\"Naive\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_naive))\n",
    "print(\"ESE:\", np.std(bias_naive, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_naive))\n",
    "print(\"Coverage:\", np.mean(cover_naive))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipcw))\n",
    "print(\"ESE:\", np.std(bias_ipcw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipcw))\n",
    "print(\"Coverage:\", np.mean(cover_ipcw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_ipsw))\n",
    "print(\"ESE:\", np.std(bias_ipsw, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_ipsw))\n",
    "print(\"Coverage:\", np.mean(cover_ipsw))\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "print(\"IPCW & IPSW\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Bias:\", np.mean(bias_full))\n",
    "print(\"ESE:\", np.std(bias_full, ddof=1))\n",
    "print(\"CLD:\", np.mean(cld_full))\n",
    "print(\"Coverage:\", np.mean(cover_full))\n",
    "print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "As this limited simulation demonstrates, ignoring non-random sampling and informative LTFU may lead to biased results. In practice, both of these are likely to occur. IPSW and IPCW provide ways to make less restrictive assumptions than approaches that assume random sampling of the target population and non-informative censoring.\n",
    "\n",
    "Furthermore, IPCW and IPSW solve different issues. IPSW are used to correct for the baseline sample not being reflective of the target population. IPCW are used to correct for LTFU for the baseline sample.\n",
    "\n",
    "### Resources\n",
    "For more detailed (and peer-reviewed) arguments on this point, I recommend the following resources:\n",
    "\n",
    "DuGoff EH, Schuler M, & Stuart EA. (2014). Generalizing observational study results: applying propensity score methods to complex surveys. *Health Services Research*, 49(1), 284-303.\n",
    "\n",
    "Lesko CR, Buchanan AL, Westreich D, Edwards JK, Hudgens MG, & Cole SR. (2017). Generalizing study results: a potential outcomes perspective. *Epidemiology (Cambridge, Mass.)*, 28(4), 553.\n",
    "\n",
    "Cole SR, & Stuart EA. (2010). Generalizing evidence from randomized clinical trials to target populations: the ACTG 320 trial. *American Journal of Epidemiology*, 172(1), 107-115.\n",
    "\n",
    "Westreich D, Edwards JK, Lesko CR, Stuart E, & Cole SR. (2017). Transportability of trial results using inverse odds of sampling weights. *American Journal of Epidemiology*, 186(8), 1010-1014.\n",
    "\n",
    "Howe CJ, Cole SR, Lau B, Napravnik S, & Eron Jr JJ. (2016). Selection bias due to loss to follow up in cohort studies. *Epidemiology (Cambridge, Mass.)*, 27(1), 91."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
